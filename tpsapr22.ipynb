{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Notebook Initialization\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # Data visualization\nfrom matplotlib.ticker import MaxNLocator\nfrom cycler import cycler\nfrom IPython.display import display\nimport datetime\nimport scipy.stats\n\nimport scipy.stats\nfrom sklearn.decomposition import PCA # Principal Component Analysis\nfrom sklearn.model_selection import GroupKFold, cross_val_score\nfrom sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier\nfrom sklearn.feature_selection import SequentialFeatureSelector\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom xgboost import XGBClassifier\nfrom sklearn.pipeline import make_pipeline\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True, figsize=(11, 5))\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n    facecolor = '#f0f3f4',\n)\nplot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n    legend=False,\n)\n\n%config InlineBackend.figure_format = 'retina'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-30T22:30:12.452884Z","iopub.execute_input":"2022-04-30T22:30:12.453521Z","iopub.status.idle":"2022-04-30T22:30:13.628435Z","shell.execute_reply.started":"2022-04-30T22:30:12.453404Z","shell.execute_reply":"2022-04-30T22:30:13.627712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:#38c9ff;letter-spacing:0.5px;overflow:hidden\"><p style=\"padding:20px;color:#FFFFFF;overflow:hidden;margin:0;font-size:110%\"><b>1 |</b>  Data Overview</p></div>\n\n## <b><span style='color:#38c9ff'>1.1</span> | Main Goal</b>\nIn this competition, you'll classify 60-second sequences of sensor data, indicating whether a subject was in either of two activity states for the duration of the sequence.\n\n## <b><span style='color:#38c9ff'>1.2</span> | Files and Field Descriptions</b>\n\n1. **train.csv** - the training set, comprising ~26,000 60-second recordings of thirteen biological sensors for almost one thousand experimental participants\n    - `sequence` - a unique id for each sequence\n    - `subject` - a unique id for the subject in the experiment\n    - `step` - time step of the recording, in one second intervals\n    - `sensor_00 - sensor_12` - the value for each of the thirteen sensors at that time step\n2. **train_labels.csv** - the class label for each sequence.\n    - `sequence` - the unique id for each sequence.\n    - `state` - the state associated to each sequence. This is the target which you are trying to predict.\n3. **test.csv** - the test set. For each of the ~12,000 sequences, you should predict a value for that sequence's state.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-apr-2022/train.csv')\ntrain_labels = pd.read_csv('../input/tabular-playground-series-apr-2022/train_labels.csv')\ntest = pd.read_csv('../input/tabular-playground-series-apr-2022/test.csv')\n\nprint(\"Train Dataset -------------------------------------------------\")\nprint(\"There are {:,} observations and {} columns in the train dataset.\".format(train.shape[0], train.shape[1]))\nprint(\"There are {} missing values in the train dataset.\".format(train.isna().sum().sum()))\nprint(\"There are {} duplicated values the train dataset.\".format(train.duplicated().sum()))\nprint(\"\")\nprint(\"Labels Dataset ------------------------------------------------\")\nprint(\"There are {:,} observations and {} columns in the labels dataset.\".format(train_labels.shape[0], train_labels.shape[1]))\nprint(\"There are {} missing values in the labels dataset.\".format(train_labels.isna().sum().sum()))\nprint(\"There are {} duplicated values the labels dataset.\".format(train_labels.duplicated().sum()))\nprint(\"\")\nprint(\"Test Dataset --------------------------------------------------\")\nprint(\"There are {:,} observations and {} columns in the test dataset.\".format(train_labels.shape[0], train_labels.shape[1]))\nprint(\"There are {} missing values in the test dataset.\".format(train_labels.isna().sum().sum()))\nprint(\"There are {} duplicated values the test dataset.\".format(train_labels.duplicated().sum()))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T17:43:46.420025Z","iopub.execute_input":"2022-04-30T17:43:46.420648Z","iopub.status.idle":"2022-04-30T17:43:56.465252Z","shell.execute_reply.started":"2022-04-30T17:43:46.420588Z","shell.execute_reply":"2022-04-30T17:43:56.464403Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"color:#03162D;border-color:#38c9ff;background-color:#d2f2ff; font-size:12px; font-family:verdana; line-height: 1.7em;\">\n    <b><span style='color:#38c9ff'>Observations</span></b> | The Train and Labels Datasets\n\n- There are **25968 Secuences** based on the `labels` dataset, and the `train` dataset has the 60 steps of each secuence, so there are **1558080 records**.\n\n- Every sequence has **13 values** (`sensor_00 - sensor_12`) and **60 steps**, so there are **780 features** in this binary classification problem\n    \n\n    ","metadata":{}},{"cell_type":"code","source":"display(train.describe(include=['float','int']).T.round(3).style.format('{:,.2f}')\n        .bar(color='#38c9ff', axis=0, vmin=0)\n        .set_caption(\"Summary statistics for Train Dataset\"))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T17:43:56.466358Z","iopub.execute_input":"2022-04-30T17:43:56.466605Z","iopub.status.idle":"2022-04-30T17:43:57.55632Z","shell.execute_reply.started":"2022-04-30T17:43:56.466571Z","shell.execute_reply":"2022-04-30T17:43:57.555547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train_labels.describe(include=['float','int']).T.round(3).style.format('{:,.2f}')\n        .bar(color='#38c9ff', axis=0, vmin=0)\n        .set_caption(\"Summary statistics for Train Labels Dataset\"))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T17:43:57.558245Z","iopub.execute_input":"2022-04-30T17:43:57.558556Z","iopub.status.idle":"2022-04-30T17:43:57.588733Z","shell.execute_reply.started":"2022-04-30T17:43:57.558513Z","shell.execute_reply":"2022-04-30T17:43:57.588175Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:#38c9ff;letter-spacing:0.5px;overflow:hidden\"><p style=\"padding:20px;color:#FFFFFF;overflow:hidden;margin:0;font-size:110%\"><b>2 |</b>  Exploratory Data Analysis</p></div>\n\n## <b><span style='color:#38c9ff'>2.1</span> | The Subjects</b>","metadata":{}},{"cell_type":"code","source":"plt.subplots(1, 2, sharey=True, figsize=(16, 4))\n\ndef plot_sequence_count_distribution(df, title):\n    temp = df.subject.value_counts().sort_values() // 60\n    plt.bar(range(len(temp)), temp, width=1, color = '#38c9ff')\n    plt.xlabel('subject')\n    plt.ylabel('sequence count')\n    plt.title(f'Sequence count distribution over {title} subjects')\n    display(temp.sort_values().rename(f'sequence count per {title} subject'))\n\nplt.subplot(1, 2, 1)\nplot_sequence_count_distribution(train, 'training')\nplt.subplot(1, 2, 2)\nplot_sequence_count_distribution(test, 'test')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T17:43:57.589714Z","iopub.execute_input":"2022-04-30T17:43:57.590386Z","iopub.status.idle":"2022-04-30T17:43:59.859024Z","shell.execute_reply.started":"2022-04-30T17:43:57.590355Z","shell.execute_reply":"2022-04-30T17:43:59.85803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = train.groupby('sequence').subject.min() # dataframe with one row per sequence\ntemp = train_labels.merge(temp, on='sequence') # adding the labels\ntemp = temp.groupby('subject').agg({'state': 'mean', 'sequence': 'count'}).rename(columns={'state': 'probability', 'sequence': 'sequence_count'})\ntemp1 = temp[temp.sequence_count >= 25].probability.rename('Probability of state==1')\n\nplt.figure(figsize=(14, 6))\n\nplt.subplot(1, 2, 1)\nplt.hist(temp1, bins=20,color = '#38c9ff')\nplt.ylabel('Subject count')\nplt.xlabel('Probability for state==1')\nplt.title('Histogram of state probabilities per subject')\n\nplt.subplot(1, 2, 2)\nplt.scatter(temp.sequence_count, temp.probability,color = '#38c9ff')\nplt.xlabel('sequence count')\nplt.ylabel('probability')\nplt.title('Probability depends on sequence count')\n\nplt.show()\n\nprint()\nprint(f\"The standard deviation of {temp[temp.sequence_count >= 25].probability.std():.2f} is much higher than 0.1.\")\nprint()\nprint('Subjects which are always in state 0:', (temp.probability == 0).sum())","metadata":{"execution":{"iopub.status.busy":"2022-04-30T17:43:59.860352Z","iopub.execute_input":"2022-04-30T17:43:59.860582Z","iopub.status.idle":"2022-04-30T17:44:00.458738Z","shell.execute_reply.started":"2022-04-30T17:43:59.860555Z","shell.execute_reply":"2022-04-30T17:44:00.457697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#38c9ff'>2.2</span> | The Sensors</b>","metadata":{}},{"cell_type":"code","source":"figure = plt.figure(figsize=(16, 8))\nfor sensor in range(13):\n    sensor_name = f\"sensor_{sensor:02d}\"\n    plt.subplot(4, 4, sensor+1)\n    plt.hist(train[sensor_name], bins=100, color = '#38c9ff')\n    plt.title(f\"{sensor_name} histogram\")\nfigure.tight_layout(h_pad=1.0, w_pad=0.5)\nplt.suptitle('Sensor Histograms Before Outlier Removal', y=1.02)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T17:44:00.46032Z","iopub.execute_input":"2022-04-30T17:44:00.461056Z","iopub.status.idle":"2022-04-30T17:44:05.64997Z","shell.execute_reply.started":"2022-04-30T17:44:00.461008Z","shell.execute_reply":"2022-04-30T17:44:05.649024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(16, 8))\nfor sensor in range(13):\n    sensor_name = f\"sensor_{sensor:02d}\"\n    plt.subplot(4, 4, sensor+1)\n    plt.hist(train[sensor_name], bins=100, color = '#38c9ff',\n             range=(train[sensor_name].quantile(0.02),\n                    train[sensor_name].quantile(0.98)))\n    plt.title(f\"{sensor_name} histogram\")\nfigure.tight_layout(h_pad=1.0, w_pad=0.5)\nplt.suptitle('Sensor Histograms After Outlier Removal', y=1.02)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T17:44:05.651439Z","iopub.execute_input":"2022-04-30T17:44:05.651683Z","iopub.status.idle":"2022-04-30T17:44:11.359172Z","shell.execute_reply.started":"2022-04-30T17:44:05.651655Z","shell.execute_reply":"2022-04-30T17:44:11.358211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sensor_name = 'sensor_12'\nplt.hist(train[sensor_name], bins=100, color='#38c9ff',\n         range=(train[sensor_name].quantile(0.15),\n                train[sensor_name].quantile(0.85)))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T17:44:11.360431Z","iopub.execute_input":"2022-04-30T17:44:11.360678Z","iopub.status.idle":"2022-04-30T17:44:11.823406Z","shell.execute_reply.started":"2022-04-30T17:44:11.360648Z","shell.execute_reply":"2022-04-30T17:44:11.822557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#38c9ff'>2.3</span> | Time Series</b>","metadata":{}},{"cell_type":"code","source":"sequences = [0, 1, 2, 8364, 15404]\nfigure, axes = plt.subplots(13, len(sequences), sharex=True, figsize=(16, 16))\nfor i, sequence in enumerate(sequences):\n    for sensor in range(13):\n        sensor_name = f\"sensor_{sensor:02d}\"\n        plt.subplot(13, len(sequences), sensor * len(sequences) + i + 1)\n        plt.plot(range(60), train[train.sequence == sequence][sensor_name],\n                color=plt.rcParams['axes.prop_cycle'].by_key()['color'][i % 10])\n        if sensor == 0: plt.title(f\"Sequence {sequence}\")\n        if sequence == sequences[0]: plt.ylabel(sensor_name)\nfigure.tight_layout(w_pad=0.1)\nplt.suptitle('Selected Time Series', y=1.02)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T17:44:11.826277Z","iopub.execute_input":"2022-04-30T17:44:11.826515Z","iopub.status.idle":"2022-04-30T17:44:20.015239Z","shell.execute_reply.started":"2022-04-30T17:44:11.826488Z","shell.execute_reply":"2022-04-30T17:44:20.014259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For every sensor: count the sequences where the sensor is stuck at a constant value\ndef stuck_at_constant(seq):\n    return seq.min() == seq.max()\n\nfor sensor in range(13):\n    sensor_name = f\"sensor_{sensor:02d}\"\n    stuck_sequences = train.groupby('sequence')[sensor_name].apply(stuck_at_constant)\n    print(f\"{sensor_name}: {stuck_sequences.sum():4d}   {train_labels[stuck_sequences].state.mean()}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-30T17:44:20.016648Z","iopub.execute_input":"2022-04-30T17:44:20.01686Z","iopub.status.idle":"2022-04-30T17:45:01.828268Z","shell.execute_reply.started":"2022-04-30T17:44:20.016835Z","shell.execute_reply":"2022-04-30T17:45:01.827189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#38c9ff'>2.4</span> | Pivoting the Data</b>","metadata":{}},{"cell_type":"code","source":"train_pivoted = train.pivot(index=['sequence', 'subject'], columns='step', values=[col for col in train.columns if 'sensor_' in col])\ntrain_pivoted","metadata":{"execution":{"iopub.status.busy":"2022-04-30T17:45:01.829493Z","iopub.execute_input":"2022-04-30T17:45:01.829842Z","iopub.status.idle":"2022-04-30T17:45:02.535479Z","shell.execute_reply.started":"2022-04-30T17:45:01.829811Z","shell.execute_reply":"2022-04-30T17:45:02.534504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = train_pivoted.sort_values(by=list(train_pivoted.columns))\nduplicates_first = temp.duplicated(keep='first')\nduplicates_last = temp.duplicated(keep='last')\ntemp['duplicates_first'] = duplicates_first\ntemp['duplicates_last'] = duplicates_last\nduplicates = temp[duplicates_first | duplicates_last]\ndisplay(duplicates)\n\nprint()\nprint('All these sequences have sensor_00 stuck at 0.000773:', duplicates['sensor_00'].apply(stuck_at_constant).all())\n\nprint()\nprint(f'Labels of the duplicates: {list(train_labels.loc[duplicates.index.get_level_values(0)].state)}')","metadata":{"execution":{"iopub.status.busy":"2022-04-30T17:45:02.537059Z","iopub.execute_input":"2022-04-30T17:45:02.537373Z","iopub.status.idle":"2022-04-30T17:45:09.894018Z","shell.execute_reply.started":"2022-04-30T17:45:02.537329Z","shell.execute_reply":"2022-04-30T17:45:09.892991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#38c9ff'>2.5</span> | PCA</b>","metadata":{}},{"cell_type":"code","source":"# Compute the PCA\n# Outlier removal or input scaling may change the PCA completely\n# whiten=True/False doesn't change the look of the diagrams (it only modifies the scale)\ndef plot_pca(df, col, title):\n    \"\"\"Plot cumulative variance and the first two components in column col of the figure.\"\"\"\n    pca = PCA()\n    #pca.fit(StandardScaler().fit_transform(train_df.drop(columns=['id', 'target'])))\n    Xt = pca.fit_transform(df.values)\n\n    # Plot the cumulative explained variance\n    plt.subplot(2, 2, col+1)\n    plt.plot(np.cumsum(pca.explained_variance_ratio_), color='#38c9ff')\n    plt.xlabel('number of components')\n    plt.ylabel('cumulative explained variance')\n    plt.title(title)\n\n    # Scatterplot of the first two dimensions\n    plt.subplot(2, 2, col+3)\n    plt.scatter(Xt[0], Xt[1], color='#38c9ff')\n    \ntemp = train_pivoted.clip(train_pivoted.quantile(0.02, axis=0).values,\n                          train_pivoted.quantile(0.98, axis=0).values, \n                          axis=1)\ntemp.pop('sensor_12')\n\nplt.figure(figsize=(12, 8))\nplot_pca(train_pivoted, 0, 'Before Outlier Removal')\nplot_pca(temp, 1, 'After Outlier Removal')\nplt.suptitle('Principal Components Analysis')\nplt.tight_layout(h_pad=1.1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T17:45:09.895514Z","iopub.execute_input":"2022-04-30T17:45:09.895839Z","iopub.status.idle":"2022-04-30T17:45:20.073981Z","shell.execute_reply.started":"2022-04-30T17:45:09.895798Z","shell.execute_reply":"2022-04-30T17:45:20.073154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:#38c9ff;letter-spacing:0.5px;overflow:hidden\"><p style=\"padding:20px;color:#FFFFFF;overflow:hidden;margin:0;font-size:110%\"><b>3 |</b>  Modeling</p></div>\n\n## <b><span style='color:#38c9ff'>3.1</span> | Feature Engineering</b>","metadata":{}},{"cell_type":"code","source":"sensors = [col for col in train.columns if 'sensor_' in col]\n\ntrain_pivoted0 = train.pivot(index=['sequence', 'subject'], columns='step', values=sensors)\ndisplay(train_pivoted0)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T17:45:20.075497Z","iopub.execute_input":"2022-04-30T17:45:20.075989Z","iopub.status.idle":"2022-04-30T17:45:20.734951Z","shell.execute_reply.started":"2022-04-30T17:45:20.075937Z","shell.execute_reply":"2022-04-30T17:45:20.733999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature engineering\ndef engineer(df):\n    new_df = pd.DataFrame([], index=df.index)\n    for sensor in sensors:\n        new_df[sensor + '_mean'] = df[sensor].mean(axis=1)\n        new_df[sensor + '_std'] = df[sensor].std(axis=1)\n        new_df[sensor + '_iqr'] = scipy.stats.iqr(df[sensor], axis=1)\n        new_df[sensor + '_sm'] = np.nan_to_num(new_df[sensor + '_std'] / \n                                               new_df[sensor + '_mean'].abs()).clip(-1e30, 1e30)\n        new_df[sensor + '_kurtosis'] = scipy.stats.kurtosis(df[sensor], axis=1)\n    new_df['sensor_02_up'] = (df.sensor_02.diff(axis=1) > 0).sum(axis=1)\n    new_df['sensor_02_down'] = (df.sensor_02.diff(axis=1) < 0).sum(axis=1)\n    new_df['sensor_02_upsum'] = df.sensor_02.diff(axis=1).clip(0, None).sum(axis=1)\n    new_df['sensor_02_downsum'] = df.sensor_02.diff(axis=1) .clip(None, 0).sum(axis=1)\n    new_df['sensor_02_upmax'] = df.sensor_02.diff(axis=1).max(axis=1)\n    new_df['sensor_02_downmax'] = df.sensor_02.diff(axis=1).min(axis=1)\n    new_df['sensor_02_upmean'] = np.nan_to_num(new_df['sensor_02_upsum'] / new_df['sensor_02_up'], posinf=40)\n    new_df['sensor_02_downmean'] = np.nan_to_num(new_df['sensor_02_downsum'] / new_df['sensor_02_down'], neginf=-40)\n    return new_df\n\ntrain_pivoted = engineer(train_pivoted0)\n\ntrain_shuffled = train_pivoted.sample(frac=1.0, random_state=1)\nlabels_shuffled = train_labels.reindex(train_shuffled.index.get_level_values('sequence'))\nlabels_shuffled = labels_shuffled[['state']].merge(train[['sequence', 'subject']].groupby('sequence').min(),\n                                                   how='left', on='sequence')\nlabels_shuffled = labels_shuffled.merge(labels_shuffled.groupby('subject').size().rename('sequence_count'),\n                                        how='left', on='subject')\ntrain_shuffled['sequence_count_of_subject'] = labels_shuffled['sequence_count'].values\n\nselected_columns = train_shuffled.columns\nprint(len(selected_columns))\n#train_shuffled.columns","metadata":{"execution":{"iopub.status.busy":"2022-04-30T17:45:20.736245Z","iopub.execute_input":"2022-04-30T17:45:20.736507Z","iopub.status.idle":"2022-04-30T17:45:22.63947Z","shell.execute_reply.started":"2022-04-30T17:45:20.736476Z","shell.execute_reply":"2022-04-30T17:45:22.638499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot dependence between every feature and the target\nncols = len(train_shuffled.columns) // 13\nplt.subplots(15, ncols, sharey=True, sharex=True, figsize=(15, 40))\nfor i, col in enumerate(train_shuffled.columns):\n    temp = pd.DataFrame({col: train_shuffled[col].values,\n                         'state': labels_shuffled.state.values})\n    temp = temp.sort_values(col)\n    temp.reset_index(inplace=True)\n    plt.subplot(15, ncols, i+1)\n    plt.scatter(temp.index, temp.state.rolling(1000).mean(), s=2,color='#38c9ff')\n    plt.xlabel(col)\n    plt.xticks([])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T17:45:22.640992Z","iopub.execute_input":"2022-04-30T17:45:22.641725Z","iopub.status.idle":"2022-04-30T17:45:35.108943Z","shell.execute_reply.started":"2022-04-30T17:45:22.641676Z","shell.execute_reply":"2022-04-30T17:45:35.106125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#38c9ff'>3.2</span> | Feature Selection</b>","metadata":{}},{"cell_type":"code","source":"# Drop some useless features\ndropped_features = ['sensor_05_kurtosis', 'sensor_08_mean',\n                    'sensor_05_std', 'sensor_06_kurtosis',\n                    'sensor_06_std', 'sensor_03_std',\n                    'sensor_02_kurtosis', 'sensor_03_kurtosis',\n                    'sensor_09_kurtosis', 'sensor_03_mean',\n                    'sensor_00_mean', 'sensor_02_iqr',\n                    'sensor_05_mean', 'sensor_06_mean',\n                    'sensor_07_std', 'sensor_10_iqr',\n                    'sensor_11_iqr', 'sensor_12_iqr',\n                    'sensor_09_mean', 'sensor_02_sm',\n                    'sensor_03_sm', 'sensor_05_iqr', \n                    'sensor_06_sm', 'sensor_09_iqr', \n                    'sensor_07_iqr', 'sensor_10_mean']\nselected_columns = [f for f in selected_columns if f not in dropped_features]\nlen(selected_columns)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T18:13:25.530457Z","iopub.execute_input":"2022-04-30T18:13:25.530799Z","iopub.status.idle":"2022-04-30T18:13:25.541075Z","shell.execute_reply.started":"2022-04-30T18:13:25.530765Z","shell.execute_reply":"2022-04-30T18:13:25.540228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sequential feature selection\n# This code is a more verbose form of scikit-learn's SequentialFeatureSelector\nestimator = HistGradientBoostingClassifier(learning_rate=0.05, max_leaf_nodes=25,\n                                       max_iter=1000, min_samples_leaf=500,\n                                       l2_regularization=1,\n                                       max_bins=255,\n                                       random_state=4, verbose=0)\n\nX, y = train_shuffled[selected_columns], labels_shuffled.state\nn_iterations, backward = 48, False\n\nif n_iterations != 0:\n    n_features = X.shape[1]\n    current_mask = np.zeros(shape=n_features, dtype=bool)\n    history = []\n    for _ in range(n_iterations):\n        candidate_feature_indices = np.flatnonzero(~current_mask)\n        scores = {}\n        for feature_idx in candidate_feature_indices:\n            candidate_mask = current_mask.copy()\n            candidate_mask[feature_idx] = True\n            X_new = X.values[:, ~candidate_mask if backward else candidate_mask]\n            scores[feature_idx] = cross_val_score(\n                estimator,\n                X_new,\n                y,\n                cv=GroupKFold(n_splits=5),\n                groups=train_shuffled.index.get_level_values('subject'),\n                scoring='roc_auc',\n                n_jobs=-1,\n            ).mean()\n            #print(f\"{str(X.columns[feature_idx]):30} {scores[feature_idx]:.3f}\")\n        new_feature_idx = max(scores, key=lambda feature_idx: scores[feature_idx])\n        current_mask[new_feature_idx] = True\n        history.append(scores[new_feature_idx])\n        new = 'Deleted' if backward else 'Added'\n        print(f'{new} feature: {str(X.columns[new_feature_idx]):30}'\n              f' {scores[new_feature_idx]:.3f}')\n\n    print()\n    plt.figure(figsize=(12, 6))\n    plt.scatter(np.arange(len(history)) + (0 if backward else 1), history, color='#38c9ff')\n    plt.ylabel('AUC')\n    plt.xlabel('Features removed' if backward else 'Features added')\n    plt.title('Sequential Feature Selection')\n    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n    plt.show()\n\n    if backward:\n        current_mask = ~current_mask\n    selected_columns = np.array(selected_columns)[current_mask]\n    print(selected_columns)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T18:14:57.467063Z","iopub.execute_input":"2022-04-30T18:14:57.467399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#38c9ff'>3.3</span> | Cross Validation</b>","metadata":{}},{"cell_type":"code","source":"%%time\n# Cross-validation of the classifier\n\nprint(f\"{len(selected_columns)} features\")\nscore_list = []\nkf = GroupKFold(n_splits=5)\nfor fold, (idx_tr, idx_va) in enumerate(kf.split(train_shuffled, groups=train_shuffled.index.get_level_values('subject'))):\n    X_tr = train_shuffled.iloc[idx_tr][selected_columns]\n    X_va = train_shuffled.iloc[idx_va][selected_columns]\n    y_tr = labels_shuffled.iloc[idx_tr].state\n    y_va = labels_shuffled.iloc[idx_va].state\n\n    model = HistGradientBoostingClassifier(learning_rate=0.05, max_leaf_nodes=25,\n                                           max_iter=1000, min_samples_leaf=500,\n                                           l2_regularization=1,\n                                           validation_fraction=0.05,\n                                           max_bins=63,\n                                           random_state=3, verbose=0)\n#     model = XGBClassifier(n_estimators=500, n_jobs=-1,\n#                           eval_metric=['logloss'],\n#                           #max_depth=10,\n#                           colsample_bytree=0.8,\n#                           #gamma=1.4,\n#                           reg_alpha=6, reg_lambda=1.5,\n#                           tree_method='hist',\n#                           learning_rate=0.03,\n#                           verbosity=1,\n#                           use_label_encoder=False, random_state=3)\n\n    if True or type(model) != XGBClassifier:\n        model.fit(X_tr.values, y_tr)\n    else:\n        model.fit(X_tr.values, y_tr, eval_set = [(X_va.values, y_va)], \n                  eval_metric = ['auc'], early_stopping_rounds=30, verbose=10)\n    try:\n        y_va_pred = model.decision_function(X_va.values) # HistGradientBoostingClassifier\n    except AttributeError:\n        try:\n            y_va_pred = model.predict_proba(X_va.values)[:,1] # XGBClassifier\n        except AttributeError:\n            y_va_pred = model.predict(X_va.values) # XGBRegressor\n    score = roc_auc_score(y_va, y_va_pred)\n    try:\n        print(f\"Fold {fold}: n_iter ={model.n_iter_:5d}    AUC = {score:.3f}\")\n    except AttributeError:\n        print(f\"Fold {fold}:                  AUC = {score:.3f}\")\n    score_list.append(score)\n    \nprint(f\"OOF AUC:                       {np.mean(score_list):.3f}\") # 0.944","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#38c9ff'>3.4</span> | ROC Curve</b>","metadata":{}},{"cell_type":"code","source":"# Plot the roc curve for the last fold\ndef plot_roc_curve(y_va, y_va_pred):\n    plt.figure(figsize=(8, 8))\n    fpr, tpr, _ = roc_curve(y_va, y_va_pred)\n    plt.plot(fpr, tpr, color='r', lw=2,color='#38c9ff')\n    plt.plot([0, 1], [0, 1], color=\"navy\", lw=1, linestyle=\"--\")\n    plt.gca().set_aspect('equal')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(\"Receiver operating characteristic\")\n    plt.show()\n\nplot_roc_curve(y_va, y_va_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#38c9ff'>3.5</span> | Test predictions and submission</b>","metadata":{}},{"cell_type":"code","source":"# Feature engineering for test\ntest_pivoted0 = test.pivot(index=['sequence', 'subject'], columns='step', values=sensors)\ntest_pivoted = engineer(test_pivoted0)\nsequence_count = test_pivoted.index.to_frame(index=False).groupby('subject').size().rename('sequence_count_of_subject')\n#display(test_pivoted.head(2))\nsubmission = pd.DataFrame({'sequence': test_pivoted.index.get_level_values('sequence')})\ntest_pivoted = test_pivoted.merge(sequence_count, how='left', on='subject')\ntest_pivoted.head(2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrain, predict and write submission\nprint(f\"{len(selected_columns)} features\")\n\npred_list = []\nfor seed in range(100):\n    X_tr = train_shuffled[selected_columns]\n    y_tr = labels_shuffled.state\n\n    model = HistGradientBoostingClassifier(learning_rate=0.05, max_leaf_nodes=25,\n                                           max_iter=1000, min_samples_leaf=500,\n                                           validation_fraction=0.05,\n                                           l2_regularization=1,\n                                           max_bins=63,\n                                           random_state=seed, verbose=0)\n    model.fit(X_tr.values, y_tr)\n    pred_list.append(scipy.stats.rankdata(model.decision_function(test_pivoted[selected_columns].values)))\n    print(f\"{seed:2}\", pred_list[-1])\nprint()\nsubmission['state'] = sum(pred_list) / len(pred_list)\nsubmission.to_csv('submission.csv', index=False)\nsubmission","metadata":{},"execution_count":null,"outputs":[]}]}