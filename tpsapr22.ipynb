{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-04-30T22:30:12.453521Z","iopub.status.busy":"2022-04-30T22:30:12.452884Z","iopub.status.idle":"2022-04-30T22:30:13.628435Z","shell.execute_reply":"2022-04-30T22:30:13.627712Z","shell.execute_reply.started":"2022-04-30T22:30:12.453404Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\user\\anaconda3\\envs\\R-LAB\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n","  from pandas import MultiIndex, Int64Index\n"]}],"source":["# Notebook Initialization\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt # Data visualization\n","from matplotlib.ticker import MaxNLocator\n","from cycler import cycler\n","from IPython.display import display\n","import datetime\n","import scipy.stats\n","\n","import scipy.stats\n","from sklearn.decomposition import PCA # Principal Component Analysis\n","from sklearn.model_selection import GroupKFold, cross_val_score\n","from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier\n","from sklearn.feature_selection import SequentialFeatureSelector\n","from sklearn.metrics import roc_auc_score, roc_curve\n","from xgboost import XGBClassifier\n","from sklearn.pipeline import make_pipeline\n","\n","# Set Matplotlib defaults\n","plt.style.use(\"seaborn-whitegrid\")\n","plt.rc(\"figure\", autolayout=True, figsize=(11, 5))\n","plt.rc(\n","    \"axes\",\n","    labelweight=\"bold\",\n","    labelsize=\"large\",\n","    titleweight=\"bold\",\n","    titlesize=14,\n","    titlepad=10,\n","    facecolor = '#f0f3f4',\n",")\n","plot_params = dict(\n","    color=\"0.75\",\n","    style=\".-\",\n","    markeredgecolor=\"0.25\",\n","    markerfacecolor=\"0.25\",\n","    legend=False,\n",")\n","\n","%config InlineBackend.figure_format = 'retina'"]},{"cell_type":"markdown","metadata":{},"source":["# <div style=\"color:white;display:fill;border-radius:5px;background-color:#38c9ff;letter-spacing:0.5px;overflow:hidden\"><p style=\"padding:20px;color:#FFFFFF;overflow:hidden;margin:0;font-size:110%\"><b>1 |</b>  Data Overview</p></div>\n","\n","## <b><span style='color:#38c9ff'>1.1</span> | Main Goal</b>\n","In this competition, you'll classify 60-second sequences of sensor data, indicating whether a subject was in either of two activity states for the duration of the sequence.\n","\n","## <b><span style='color:#38c9ff'>1.2</span> | Files and Field Descriptions</b>\n","\n","1. **train.csv** - the training set, comprising ~26,000 60-second recordings of thirteen biological sensors for almost one thousand experimental participants\n","    - `sequence` - a unique id for each sequence\n","    - `subject` - a unique id for the subject in the experiment\n","    - `step` - time step of the recording, in one second intervals\n","    - `sensor_00 - sensor_12` - the value for each of the thirteen sensors at that time step\n","2. **train_labels.csv** - the class label for each sequence.\n","    - `sequence` - the unique id for each sequence.\n","    - `state` - the state associated to each sequence. This is the target which you are trying to predict.\n","3. **test.csv** - the test set. For each of the ~12,000 sequences, you should predict a value for that sequence's state."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T17:43:46.420648Z","iopub.status.busy":"2022-04-30T17:43:46.420025Z","iopub.status.idle":"2022-04-30T17:43:56.465252Z","shell.execute_reply":"2022-04-30T17:43:56.464403Z","shell.execute_reply.started":"2022-04-30T17:43:46.420588Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["train = pd.read_csv('../input/tabular-playground-series-apr-2022/train.csv')\n","train_labels = pd.read_csv('../input/tabular-playground-series-apr-2022/train_labels.csv')\n","test = pd.read_csv('../input/tabular-playground-series-apr-2022/test.csv')\n","\n","print(\"Train Dataset -------------------------------------------------\")\n","print(\"There are {:,} observations and {} columns in the train dataset.\".format(train.shape[0], train.shape[1]))\n","print(\"There are {} missing values in the train dataset.\".format(train.isna().sum().sum()))\n","print(\"There are {} duplicated values the train dataset.\".format(train.duplicated().sum()))\n","print(\"\")\n","print(\"Labels Dataset ------------------------------------------------\")\n","print(\"There are {:,} observations and {} columns in the labels dataset.\".format(train_labels.shape[0], train_labels.shape[1]))\n","print(\"There are {} missing values in the labels dataset.\".format(train_labels.isna().sum().sum()))\n","print(\"There are {} duplicated values the labels dataset.\".format(train_labels.duplicated().sum()))\n","print(\"\")\n","print(\"Test Dataset --------------------------------------------------\")\n","print(\"There are {:,} observations and {} columns in the test dataset.\".format(train_labels.shape[0], train_labels.shape[1]))\n","print(\"There are {} missing values in the test dataset.\".format(train_labels.isna().sum().sum()))\n","print(\"There are {} duplicated values the test dataset.\".format(train_labels.duplicated().sum()))"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\" style=\"color:#03162D;border-color:#38c9ff;background-color:#d2f2ff; font-size:12px; font-family:verdana; line-height: 1.7em;\">\n","    <b><span style='color:#38c9ff'>Observations</span></b> | The Train and Labels Datasets\n","\n","- There are **25968 Secuences** based on the `labels` dataset, and the `train` dataset has the 60 steps of each secuence, so there are **1558080 records**.\n","\n","- Every sequence has **13 values** (`sensor_00 - sensor_12`) and **60 steps**, so there are **780 features** in this binary classification problem\n","    \n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T17:43:56.466605Z","iopub.status.busy":"2022-04-30T17:43:56.466358Z","iopub.status.idle":"2022-04-30T17:43:57.55632Z","shell.execute_reply":"2022-04-30T17:43:57.555547Z","shell.execute_reply.started":"2022-04-30T17:43:56.466571Z"},"trusted":true},"outputs":[],"source":["display(train.describe(include=['float','int']).T.round(3).style.format('{:,.2f}')\n","        .bar(color='#38c9ff', axis=0, vmin=0)\n","        .set_caption(\"Summary statistics for Train Dataset\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T17:43:57.558556Z","iopub.status.busy":"2022-04-30T17:43:57.558245Z","iopub.status.idle":"2022-04-30T17:43:57.588733Z","shell.execute_reply":"2022-04-30T17:43:57.588175Z","shell.execute_reply.started":"2022-04-30T17:43:57.558513Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["display(train_labels.describe(include=['float','int']).T.round(3).style.format('{:,.2f}')\n","        .bar(color='#38c9ff', axis=0, vmin=0)\n","        .set_caption(\"Summary statistics for Train Labels Dataset\"))"]},{"cell_type":"markdown","metadata":{},"source":["# <div style=\"color:white;display:fill;border-radius:5px;background-color:#38c9ff;letter-spacing:0.5px;overflow:hidden\"><p style=\"padding:20px;color:#FFFFFF;overflow:hidden;margin:0;font-size:110%\"><b>2 |</b>  Exploratory Data Analysis</p></div>\n","\n","## <b><span style='color:#38c9ff'>2.1</span> | The Subjects</b>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T17:43:57.590386Z","iopub.status.busy":"2022-04-30T17:43:57.589714Z","iopub.status.idle":"2022-04-30T17:43:59.859024Z","shell.execute_reply":"2022-04-30T17:43:59.85803Z","shell.execute_reply.started":"2022-04-30T17:43:57.590355Z"},"trusted":true},"outputs":[],"source":["plt.subplots(1, 2, sharey=True, figsize=(16, 4))\n","\n","def plot_sequence_count_distribution(df, title):\n","    temp = df.subject.value_counts().sort_values() // 60\n","    plt.bar(range(len(temp)), temp, width=1, color = '#38c9ff')\n","    plt.xlabel('subject')\n","    plt.ylabel('sequence count')\n","    plt.title(f'Sequence count distribution over {title} subjects')\n","    display(temp.sort_values().rename(f'sequence count per {title} subject'))\n","\n","plt.subplot(1, 2, 1)\n","plot_sequence_count_distribution(train, 'training')\n","plt.subplot(1, 2, 2)\n","plot_sequence_count_distribution(test, 'test')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T17:43:59.860582Z","iopub.status.busy":"2022-04-30T17:43:59.860352Z","iopub.status.idle":"2022-04-30T17:44:00.458738Z","shell.execute_reply":"2022-04-30T17:44:00.457697Z","shell.execute_reply.started":"2022-04-30T17:43:59.860555Z"},"trusted":true},"outputs":[],"source":["temp = train.groupby('sequence').subject.min() # dataframe with one row per sequence\n","temp = train_labels.merge(temp, on='sequence') # adding the labels\n","temp = temp.groupby('subject').agg({'state': 'mean', 'sequence': 'count'}).rename(columns={'state': 'probability', 'sequence': 'sequence_count'})\n","temp1 = temp[temp.sequence_count >= 25].probability.rename('Probability of state==1')\n","\n","plt.figure(figsize=(14, 6))\n","\n","plt.subplot(1, 2, 1)\n","plt.hist(temp1, bins=20,color = '#38c9ff')\n","plt.ylabel('Subject count')\n","plt.xlabel('Probability for state==1')\n","plt.title('Histogram of state probabilities per subject')\n","\n","plt.subplot(1, 2, 2)\n","plt.scatter(temp.sequence_count, temp.probability,color = '#38c9ff')\n","plt.xlabel('sequence count')\n","plt.ylabel('probability')\n","plt.title('Probability depends on sequence count')\n","\n","plt.show()\n","\n","print()\n","print(f\"The standard deviation of {temp[temp.sequence_count >= 25].probability.std():.2f} is much higher than 0.1.\")\n","print()\n","print('Subjects which are always in state 0:', (temp.probability == 0).sum())"]},{"cell_type":"markdown","metadata":{},"source":["## <b><span style='color:#38c9ff'>2.2</span> | The Sensors</b>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T17:44:00.461056Z","iopub.status.busy":"2022-04-30T17:44:00.46032Z","iopub.status.idle":"2022-04-30T17:44:05.64997Z","shell.execute_reply":"2022-04-30T17:44:05.649024Z","shell.execute_reply.started":"2022-04-30T17:44:00.461008Z"},"trusted":true},"outputs":[],"source":["figure = plt.figure(figsize=(16, 8))\n","for sensor in range(13):\n","    sensor_name = f\"sensor_{sensor:02d}\"\n","    plt.subplot(4, 4, sensor+1)\n","    plt.hist(train[sensor_name], bins=100, color = '#38c9ff')\n","    plt.title(f\"{sensor_name} histogram\")\n","figure.tight_layout(h_pad=1.0, w_pad=0.5)\n","plt.suptitle('Sensor Histograms Before Outlier Removal', y=1.02)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T17:44:05.651683Z","iopub.status.busy":"2022-04-30T17:44:05.651439Z","iopub.status.idle":"2022-04-30T17:44:11.359172Z","shell.execute_reply":"2022-04-30T17:44:11.358211Z","shell.execute_reply.started":"2022-04-30T17:44:05.651655Z"},"trusted":true},"outputs":[],"source":["figure = plt.figure(figsize=(16, 8))\n","for sensor in range(13):\n","    sensor_name = f\"sensor_{sensor:02d}\"\n","    plt.subplot(4, 4, sensor+1)\n","    plt.hist(train[sensor_name], bins=100, color = '#38c9ff',\n","             range=(train[sensor_name].quantile(0.02),\n","                    train[sensor_name].quantile(0.98)))\n","    plt.title(f\"{sensor_name} histogram\")\n","figure.tight_layout(h_pad=1.0, w_pad=0.5)\n","plt.suptitle('Sensor Histograms After Outlier Removal', y=1.02)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T17:44:11.360678Z","iopub.status.busy":"2022-04-30T17:44:11.360431Z","iopub.status.idle":"2022-04-30T17:44:11.823406Z","shell.execute_reply":"2022-04-30T17:44:11.822557Z","shell.execute_reply.started":"2022-04-30T17:44:11.360648Z"},"trusted":true},"outputs":[],"source":["sensor_name = 'sensor_12'\n","plt.hist(train[sensor_name], bins=100, color='#38c9ff',\n","         range=(train[sensor_name].quantile(0.15),\n","                train[sensor_name].quantile(0.85)))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## <b><span style='color:#38c9ff'>2.3</span> | Time Series</b>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T17:44:11.826515Z","iopub.status.busy":"2022-04-30T17:44:11.826277Z","iopub.status.idle":"2022-04-30T17:44:20.015239Z","shell.execute_reply":"2022-04-30T17:44:20.014259Z","shell.execute_reply.started":"2022-04-30T17:44:11.826488Z"},"trusted":true},"outputs":[],"source":["sequences = [0, 1, 2, 8364, 15404]\n","figure, axes = plt.subplots(13, len(sequences), sharex=True, figsize=(16, 16))\n","for i, sequence in enumerate(sequences):\n","    for sensor in range(13):\n","        sensor_name = f\"sensor_{sensor:02d}\"\n","        plt.subplot(13, len(sequences), sensor * len(sequences) + i + 1)\n","        plt.plot(range(60), train[train.sequence == sequence][sensor_name],\n","                color=plt.rcParams['axes.prop_cycle'].by_key()['color'][i % 10])\n","        if sensor == 0: plt.title(f\"Sequence {sequence}\")\n","        if sequence == sequences[0]: plt.ylabel(sensor_name)\n","figure.tight_layout(w_pad=0.1)\n","plt.suptitle('Selected Time Series', y=1.02)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T17:44:20.01686Z","iopub.status.busy":"2022-04-30T17:44:20.016648Z","iopub.status.idle":"2022-04-30T17:45:01.828268Z","shell.execute_reply":"2022-04-30T17:45:01.827189Z","shell.execute_reply.started":"2022-04-30T17:44:20.016835Z"},"trusted":true},"outputs":[],"source":["# For every sensor: count the sequences where the sensor is stuck at a constant value\n","def stuck_at_constant(seq):\n","    return seq.min() == seq.max()\n","\n","for sensor in range(13):\n","    sensor_name = f\"sensor_{sensor:02d}\"\n","    stuck_sequences = train.groupby('sequence')[sensor_name].apply(stuck_at_constant)\n","    print(f\"{sensor_name}: {stuck_sequences.sum():4d}   {train_labels[stuck_sequences].state.mean()}\")"]},{"cell_type":"markdown","metadata":{},"source":["## <b><span style='color:#38c9ff'>2.4</span> | Pivoting the Data</b>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T17:45:01.829842Z","iopub.status.busy":"2022-04-30T17:45:01.829493Z","iopub.status.idle":"2022-04-30T17:45:02.535479Z","shell.execute_reply":"2022-04-30T17:45:02.534504Z","shell.execute_reply.started":"2022-04-30T17:45:01.829811Z"},"trusted":true},"outputs":[],"source":["train_pivoted = train.pivot(index=['sequence', 'subject'], columns='step', values=[col for col in train.columns if 'sensor_' in col])\n","train_pivoted"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T17:45:02.537373Z","iopub.status.busy":"2022-04-30T17:45:02.537059Z","iopub.status.idle":"2022-04-30T17:45:09.894018Z","shell.execute_reply":"2022-04-30T17:45:09.892991Z","shell.execute_reply.started":"2022-04-30T17:45:02.537329Z"},"trusted":true},"outputs":[],"source":["temp = train_pivoted.sort_values(by=list(train_pivoted.columns))\n","duplicates_first = temp.duplicated(keep='first')\n","duplicates_last = temp.duplicated(keep='last')\n","temp['duplicates_first'] = duplicates_first\n","temp['duplicates_last'] = duplicates_last\n","duplicates = temp[duplicates_first | duplicates_last]\n","display(duplicates)\n","\n","print()\n","print('All these sequences have sensor_00 stuck at 0.000773:', duplicates['sensor_00'].apply(stuck_at_constant).all())\n","\n","print()\n","print(f'Labels of the duplicates: {list(train_labels.loc[duplicates.index.get_level_values(0)].state)}')"]},{"cell_type":"markdown","metadata":{},"source":["## <b><span style='color:#38c9ff'>2.5</span> | PCA</b>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T17:45:09.895839Z","iopub.status.busy":"2022-04-30T17:45:09.895514Z","iopub.status.idle":"2022-04-30T17:45:20.073981Z","shell.execute_reply":"2022-04-30T17:45:20.073154Z","shell.execute_reply.started":"2022-04-30T17:45:09.895798Z"},"trusted":true},"outputs":[],"source":["# Compute the PCA\n","# Outlier removal or input scaling may change the PCA completely\n","# whiten=True/False doesn't change the look of the diagrams (it only modifies the scale)\n","def plot_pca(df, col, title):\n","    \"\"\"Plot cumulative variance and the first two components in column col of the figure.\"\"\"\n","    pca = PCA()\n","    #pca.fit(StandardScaler().fit_transform(train_df.drop(columns=['id', 'target'])))\n","    Xt = pca.fit_transform(df.values)\n","\n","    # Plot the cumulative explained variance\n","    plt.subplot(2, 2, col+1)\n","    plt.plot(np.cumsum(pca.explained_variance_ratio_), color='#38c9ff')\n","    plt.xlabel('number of components')\n","    plt.ylabel('cumulative explained variance')\n","    plt.title(title)\n","\n","    # Scatterplot of the first two dimensions\n","    plt.subplot(2, 2, col+3)\n","    plt.scatter(Xt[0], Xt[1], color='#38c9ff')\n","    \n","temp = train_pivoted.clip(train_pivoted.quantile(0.02, axis=0).values,\n","                          train_pivoted.quantile(0.98, axis=0).values, \n","                          axis=1)\n","temp.pop('sensor_12')\n","\n","plt.figure(figsize=(12, 8))\n","plot_pca(train_pivoted, 0, 'Before Outlier Removal')\n","plot_pca(temp, 1, 'After Outlier Removal')\n","plt.suptitle('Principal Components Analysis')\n","plt.tight_layout(h_pad=1.1)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# <div style=\"color:white;display:fill;border-radius:5px;background-color:#38c9ff;letter-spacing:0.5px;overflow:hidden\"><p style=\"padding:20px;color:#FFFFFF;overflow:hidden;margin:0;font-size:110%\"><b>3 |</b>  Modeling</p></div>\n","\n","## <b><span style='color:#38c9ff'>3.1</span> | Feature Engineering</b>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T17:45:20.075989Z","iopub.status.busy":"2022-04-30T17:45:20.075497Z","iopub.status.idle":"2022-04-30T17:45:20.734951Z","shell.execute_reply":"2022-04-30T17:45:20.733999Z","shell.execute_reply.started":"2022-04-30T17:45:20.075937Z"},"trusted":true},"outputs":[],"source":["sensors = [col for col in train.columns if 'sensor_' in col]\n","\n","train_pivoted0 = train.pivot(index=['sequence', 'subject'], columns='step', values=sensors)\n","display(train_pivoted0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T17:45:20.736507Z","iopub.status.busy":"2022-04-30T17:45:20.736245Z","iopub.status.idle":"2022-04-30T17:45:22.63947Z","shell.execute_reply":"2022-04-30T17:45:22.638499Z","shell.execute_reply.started":"2022-04-30T17:45:20.736476Z"},"trusted":true},"outputs":[],"source":["# Feature engineering\n","def engineer(df):\n","    new_df = pd.DataFrame([], index=df.index)\n","    for sensor in sensors:\n","        new_df[sensor + '_mean'] = df[sensor].mean(axis=1)\n","        new_df[sensor + '_std'] = df[sensor].std(axis=1)\n","        new_df[sensor + '_iqr'] = scipy.stats.iqr(df[sensor], axis=1)\n","        new_df[sensor + '_sm'] = np.nan_to_num(new_df[sensor + '_std'] / \n","                                               new_df[sensor + '_mean'].abs()).clip(-1e30, 1e30)\n","        new_df[sensor + '_kurtosis'] = scipy.stats.kurtosis(df[sensor], axis=1)\n","    new_df['sensor_02_up'] = (df.sensor_02.diff(axis=1) > 0).sum(axis=1)\n","    new_df['sensor_02_down'] = (df.sensor_02.diff(axis=1) < 0).sum(axis=1)\n","    new_df['sensor_02_upsum'] = df.sensor_02.diff(axis=1).clip(0, None).sum(axis=1)\n","    new_df['sensor_02_downsum'] = df.sensor_02.diff(axis=1) .clip(None, 0).sum(axis=1)\n","    new_df['sensor_02_upmax'] = df.sensor_02.diff(axis=1).max(axis=1)\n","    new_df['sensor_02_downmax'] = df.sensor_02.diff(axis=1).min(axis=1)\n","    new_df['sensor_02_upmean'] = np.nan_to_num(new_df['sensor_02_upsum'] / new_df['sensor_02_up'], posinf=40)\n","    new_df['sensor_02_downmean'] = np.nan_to_num(new_df['sensor_02_downsum'] / new_df['sensor_02_down'], neginf=-40)\n","    return new_df\n","\n","train_pivoted = engineer(train_pivoted0)\n","\n","train_shuffled = train_pivoted.sample(frac=1.0, random_state=1)\n","labels_shuffled = train_labels.reindex(train_shuffled.index.get_level_values('sequence'))\n","labels_shuffled = labels_shuffled[['state']].merge(train[['sequence', 'subject']].groupby('sequence').min(),\n","                                                   how='left', on='sequence')\n","labels_shuffled = labels_shuffled.merge(labels_shuffled.groupby('subject').size().rename('sequence_count'),\n","                                        how='left', on='subject')\n","train_shuffled['sequence_count_of_subject'] = labels_shuffled['sequence_count'].values\n","\n","selected_columns = train_shuffled.columns\n","print(len(selected_columns))\n","#train_shuffled.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T17:45:22.641725Z","iopub.status.busy":"2022-04-30T17:45:22.640992Z","iopub.status.idle":"2022-04-30T17:45:35.108943Z","shell.execute_reply":"2022-04-30T17:45:35.106125Z","shell.execute_reply.started":"2022-04-30T17:45:22.641676Z"},"trusted":true},"outputs":[],"source":["# Plot dependence between every feature and the target\n","ncols = len(train_shuffled.columns) // 13\n","plt.subplots(15, ncols, sharey=True, sharex=True, figsize=(15, 40))\n","for i, col in enumerate(train_shuffled.columns):\n","    temp = pd.DataFrame({col: train_shuffled[col].values,\n","                         'state': labels_shuffled.state.values})\n","    temp = temp.sort_values(col)\n","    temp.reset_index(inplace=True)\n","    plt.subplot(15, ncols, i+1)\n","    plt.scatter(temp.index, temp.state.rolling(1000).mean(), s=2,color='#38c9ff')\n","    plt.xlabel(col)\n","    plt.xticks([])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## <b><span style='color:#38c9ff'>3.2</span> | Feature Selection</b>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T18:13:25.530799Z","iopub.status.busy":"2022-04-30T18:13:25.530457Z","iopub.status.idle":"2022-04-30T18:13:25.541075Z","shell.execute_reply":"2022-04-30T18:13:25.540228Z","shell.execute_reply.started":"2022-04-30T18:13:25.530765Z"},"trusted":true},"outputs":[],"source":["# Drop some useless features\n","dropped_features = ['sensor_05_kurtosis', 'sensor_08_mean',\n","                    'sensor_05_std', 'sensor_06_kurtosis',\n","                    'sensor_06_std', 'sensor_03_std',\n","                    'sensor_02_kurtosis', 'sensor_03_kurtosis',\n","                    'sensor_09_kurtosis', 'sensor_03_mean',\n","                    'sensor_00_mean', 'sensor_02_iqr',\n","                    'sensor_05_mean', 'sensor_06_mean',\n","                    'sensor_07_std', 'sensor_10_iqr',\n","                    'sensor_11_iqr', 'sensor_12_iqr',\n","                    'sensor_09_mean', 'sensor_02_sm',\n","                    'sensor_03_sm', 'sensor_05_iqr', \n","                    'sensor_06_sm', 'sensor_09_iqr', \n","                    'sensor_07_iqr', 'sensor_10_mean']\n","selected_columns = [f for f in selected_columns if f not in dropped_features]\n","len(selected_columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T18:14:57.467399Z","iopub.status.busy":"2022-04-30T18:14:57.467063Z"},"trusted":true},"outputs":[],"source":["# Sequential feature selection\n","# This code is a more verbose form of scikit-learn's SequentialFeatureSelector\n","estimator = HistGradientBoostingClassifier(learning_rate=0.05, max_leaf_nodes=25,\n","                                       max_iter=1000, min_samples_leaf=500,\n","                                       l2_regularization=1,\n","                                       max_bins=255,\n","                                       random_state=4, verbose=0)\n","\n","X, y = train_shuffled[selected_columns], labels_shuffled.state\n","n_iterations, backward = 48, False\n","\n","if n_iterations != 0:\n","    n_features = X.shape[1]\n","    current_mask = np.zeros(shape=n_features, dtype=bool)\n","    history = []\n","    for _ in range(n_iterations):\n","        candidate_feature_indices = np.flatnonzero(~current_mask)\n","        scores = {}\n","        for feature_idx in candidate_feature_indices:\n","            candidate_mask = current_mask.copy()\n","            candidate_mask[feature_idx] = True\n","            X_new = X.values[:, ~candidate_mask if backward else candidate_mask]\n","            scores[feature_idx] = cross_val_score(\n","                estimator,\n","                X_new,\n","                y,\n","                cv=GroupKFold(n_splits=5),\n","                groups=train_shuffled.index.get_level_values('subject'),\n","                scoring='roc_auc',\n","                n_jobs=-1,\n","            ).mean()\n","            #print(f\"{str(X.columns[feature_idx]):30} {scores[feature_idx]:.3f}\")\n","        new_feature_idx = max(scores, key=lambda feature_idx: scores[feature_idx])\n","        current_mask[new_feature_idx] = True\n","        history.append(scores[new_feature_idx])\n","        new = 'Deleted' if backward else 'Added'\n","        print(f'{new} feature: {str(X.columns[new_feature_idx]):30}'\n","              f' {scores[new_feature_idx]:.3f}')\n","\n","    print()\n","    plt.figure(figsize=(12, 6))\n","    plt.scatter(np.arange(len(history)) + (0 if backward else 1), history, color='#38c9ff')\n","    plt.ylabel('AUC')\n","    plt.xlabel('Features removed' if backward else 'Features added')\n","    plt.title('Sequential Feature Selection')\n","    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n","    plt.show()\n","\n","    if backward:\n","        current_mask = ~current_mask\n","    selected_columns = np.array(selected_columns)[current_mask]\n","    print(selected_columns)"]},{"cell_type":"markdown","metadata":{},"source":["## <b><span style='color:#38c9ff'>3.3</span> | Cross Validation</b>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","# Cross-validation of the classifier\n","\n","print(f\"{len(selected_columns)} features\")\n","score_list = []\n","kf = GroupKFold(n_splits=5)\n","for fold, (idx_tr, idx_va) in enumerate(kf.split(train_shuffled, groups=train_shuffled.index.get_level_values('subject'))):\n","    X_tr = train_shuffled.iloc[idx_tr][selected_columns]\n","    X_va = train_shuffled.iloc[idx_va][selected_columns]\n","    y_tr = labels_shuffled.iloc[idx_tr].state\n","    y_va = labels_shuffled.iloc[idx_va].state\n","\n","    model = HistGradientBoostingClassifier(learning_rate=0.05, max_leaf_nodes=25,\n","                                           max_iter=1000, min_samples_leaf=500,\n","                                           l2_regularization=1,\n","                                           validation_fraction=0.05,\n","                                           max_bins=63,\n","                                           random_state=3, verbose=0)\n","#     model = XGBClassifier(n_estimators=500, n_jobs=-1,\n","#                           eval_metric=['logloss'],\n","#                           #max_depth=10,\n","#                           colsample_bytree=0.8,\n","#                           #gamma=1.4,\n","#                           reg_alpha=6, reg_lambda=1.5,\n","#                           tree_method='hist',\n","#                           learning_rate=0.03,\n","#                           verbosity=1,\n","#                           use_label_encoder=False, random_state=3)\n","\n","    if True or type(model) != XGBClassifier:\n","        model.fit(X_tr.values, y_tr)\n","    else:\n","        model.fit(X_tr.values, y_tr, eval_set = [(X_va.values, y_va)], \n","                  eval_metric = ['auc'], early_stopping_rounds=30, verbose=10)\n","    try:\n","        y_va_pred = model.decision_function(X_va.values) # HistGradientBoostingClassifier\n","    except AttributeError:\n","        try:\n","            y_va_pred = model.predict_proba(X_va.values)[:,1] # XGBClassifier\n","        except AttributeError:\n","            y_va_pred = model.predict(X_va.values) # XGBRegressor\n","    score = roc_auc_score(y_va, y_va_pred)\n","    try:\n","        print(f\"Fold {fold}: n_iter ={model.n_iter_:5d}    AUC = {score:.3f}\")\n","    except AttributeError:\n","        print(f\"Fold {fold}:                  AUC = {score:.3f}\")\n","    score_list.append(score)\n","    \n","print(f\"OOF AUC:                       {np.mean(score_list):.3f}\") # 0.944"]},{"cell_type":"markdown","metadata":{},"source":["## <b><span style='color:#38c9ff'>3.4</span> | ROC Curve</b>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the roc curve for the last fold\n","def plot_roc_curve(y_va, y_va_pred):\n","    plt.figure(figsize=(8, 8))\n","    fpr, tpr, _ = roc_curve(y_va, y_va_pred)\n","    plt.plot(fpr, tpr, color='r', lw=2,color='#38c9ff')\n","    plt.plot([0, 1], [0, 1], color=\"navy\", lw=1, linestyle=\"--\")\n","    plt.gca().set_aspect('equal')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.0])\n","    plt.xlabel(\"False Positive Rate\")\n","    plt.ylabel(\"True Positive Rate\")\n","    plt.title(\"Receiver operating characteristic\")\n","    plt.show()\n","\n","plot_roc_curve(y_va, y_va_pred)"]},{"cell_type":"markdown","metadata":{},"source":["## <b><span style='color:#38c9ff'>3.5</span> | Test predictions and submission</b>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Feature engineering for test\n","test_pivoted0 = test.pivot(index=['sequence', 'subject'], columns='step', values=sensors)\n","test_pivoted = engineer(test_pivoted0)\n","sequence_count = test_pivoted.index.to_frame(index=False).groupby('subject').size().rename('sequence_count_of_subject')\n","#display(test_pivoted.head(2))\n","submission = pd.DataFrame({'sequence': test_pivoted.index.get_level_values('sequence')})\n","test_pivoted = test_pivoted.merge(sequence_count, how='left', on='subject')\n","test_pivoted.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Retrain, predict and write submission\n","print(f\"{len(selected_columns)} features\")\n","\n","pred_list = []\n","for seed in range(100):\n","    X_tr = train_shuffled[selected_columns]\n","    y_tr = labels_shuffled.state\n","\n","    model = HistGradientBoostingClassifier(learning_rate=0.05, max_leaf_nodes=25,\n","                                           max_iter=1000, min_samples_leaf=500,\n","                                           validation_fraction=0.05,\n","                                           l2_regularization=1,\n","                                           max_bins=63,\n","                                           random_state=seed, verbose=0)\n","    model.fit(X_tr.values, y_tr)\n","    pred_list.append(scipy.stats.rankdata(model.decision_function(test_pivoted[selected_columns].values)))\n","    print(f\"{seed:2}\", pred_list[-1])\n","print()\n","submission['state'] = sum(pred_list) / len(pred_list)\n","submission.to_csv('submission.csv', index=False)\n","submission"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
